{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92dec41-9888-41d6-9531-dd5bcd613e3c",
   "metadata": {},
   "source": [
    "# Ayush Patel\n",
    "## NUID: 002765119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6a9ad3-0123-452e-b6e9-cbd4b904e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec72a-500b-42b3-b3f2-5236d1711ed5",
   "metadata": {},
   "source": [
    "# Problem 1 <br>\n",
    "<b>Note: </b> : You need to install (!pip install opencv-python) to import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d59b77a9-d3a8-4bbf-bb5c-d461bfa0256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 81.8875\n",
      "Testing Accuracy: 76.4\n"
     ]
    }
   ],
   "source": [
    "train_data = np.loadtxt('trainPB1.txt')\n",
    "train_labels = train_data[:, 0]\n",
    "train_pixels = train_data[:, 1:]\n",
    "\n",
    "test_data = np.loadtxt('testPB1.txt')\n",
    "test_labels = test_data[:, 0]\n",
    "test_pixels = test_data[:, 1:]\n",
    "\n",
    "# Applying Gaussian Blur (Reason is stated below)\n",
    "train_pixels = np.array([cv2.GaussianBlur(p.reshape(28, 28), (5, 5), 0).ravel() for p in train_pixels])\n",
    "test_pixels = np.array([cv2.GaussianBlur(p.reshape(28, 28), (5, 5), 0).ravel() for p in test_pixels])\n",
    "\n",
    "# KNN from scratch\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        distances = euclidean_distances(X_test, self.X_train)\n",
    "        for i in range(X_test.shape[0]):\n",
    "            indices = np.argsort(distances[i])[:self.k]\n",
    "            k_nearest_labels = [self.y_train[j] for j in indices]\n",
    "            y_pred.append(max(k_nearest_labels, key = k_nearest_labels.count))\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        return (y_pred == y_test).mean()\n",
    "\n",
    "knn = KNN(k = 20)\n",
    "\n",
    "# Training the classifier\n",
    "knn.fit(train_pixels, train_labels)\n",
    "\n",
    "# Predicting labels for the test data\n",
    "test_pred = knn.predict(test_pixels)\n",
    "\n",
    "# Evaluate training performance\n",
    "train_acc = (knn.score(train_pixels, train_labels))*100\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "\n",
    "# Evaluate testing performance\n",
    "test_acc = (knn.score(test_pixels, test_labels))*100\n",
    "print(\"Testing Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826baae-3435-4255-9624-1cb92b194627",
   "metadata": {},
   "source": [
    "<b> Reason: </b> <br>\n",
    "In this code, the Gaussian Blur function from OpenCV library is applied to each image in the training and testing datasets using a kernel size of (5, 5) and sigma (standard deviation) value of 0. The blurred images are then reshaped back to a 1D vector and used for training and testing the KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b1e96-4d0a-4757-9af9-8874677831e6",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c45460-e28f-4d06-8c78-d2c10f923642",
   "metadata": {},
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8818ce4d-a701-4c9b-9f98-2e9fc9633302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = []\n",
    "for line in open('studentgrades_pb2.txt'):\n",
    "    line_l = [int(x) for x in line.split(' ')]\n",
    "    data.append(line_l)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72649e9-b04d-495a-abde-cb4c4ad69f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(data, num_sessions = 50, num_students = 20, num_quizzes = 3, num_iterations = 1000):\n",
    "    # Giving equal probability for each quiz\n",
    "    quiz_probabilities = [1/num_quizzes] * num_quizzes\n",
    "    # Initializing a random question probability\n",
    "    question_probabilities = [random.random() for _ in range(num_quizzes)]\n",
    "    question_probabilities = [pi / sum(question_probabilities) for pi in question_probabilities]\n",
    "\n",
    "    # EM algorithm \n",
    "    for i in range(num_iterations):\n",
    "        # E-step\n",
    "        session_quiz_probabilities = []\n",
    "        for session_index in range(num_sessions):\n",
    "            current_probs = []\n",
    "            for quiz_index in range(num_quizzes):\n",
    "                likelihood = 1\n",
    "                for student_index in range(num_students):\n",
    "                    if data[session_index][student_index] == 1:\n",
    "                        likelihood *= question_probabilities[quiz_index]\n",
    "                    else:\n",
    "                        likelihood *= (1 - question_probabilities[quiz_index])\n",
    "                current_probs.append(quiz_probabilities[quiz_index] * likelihood)\n",
    "            session_quiz_probabilities.append(current_probs)\n",
    "        session_quiz_probabilities = [[w / sum(current_probs) for w in current_probs] for current_probs in session_quiz_probabilities]\n",
    "\n",
    "        # M-step\n",
    "        for quiz_index in range(num_quizzes):\n",
    "            quiz_probabilities[quiz_index] = sum(session_quiz_probabilities[session_index][quiz_index] for session_index in range(num_sessions)) / num_sessions\n",
    "            question_probabilities[quiz_index] = sum(session_quiz_probabilities[session_index][quiz_index] * sum(data[session_index][student_index] for student_index in range(num_students)) for session_index in range(num_sessions)) / (sum(session_quiz_probabilities[session_index][quiz_index] for session_index in range(num_sessions)) * num_students)\n",
    "\n",
    "    return question_probabilities, quiz_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522b80d5-73c2-4b80-a4df-8aa9291235e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the EM Algorithm\n",
    "question_probabilities, quiz_probabilities = EM(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed12e847-01e3-48c2-babe-26d6ec12c150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of solving probelm [0.6100378318845449, 0.9317285332315947, 0.23691866848935975]\n",
      "Quiz selection probabilities:  [0.5146283397819821, 0.17855767772923006, 0.30681398248878794]\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "print(\"Probability of solving probelm\", question_probabilities)\n",
    "print(\"Quiz selection probabilities: \", quiz_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488fe93-bbdd-4067-96d0-84e541d622e9",
   "metadata": {},
   "source": [
    "<b>Explaination: </b> <br>\n",
    "The function takes in several parameters including the data about student responses, the number of quiz sessions, students, and quizzes, and the number of iterations to run the algorithm. The function then initializes the quiz probabilities as equal for all quizzes and the question probabilities as random values that sum to 1.\n",
    "\n",
    "The EM algorithm is then performed. In the E-step, the algorithm calculates the probability of a student answering a question correctly given the quiz and question probabilities. In the M-step, the algorithm updates the quiz and question probabilities based on the probabilities calculated in the E-step.\n",
    "\n",
    "The function repeats the E-step and M-step for the number of iterations specified and returns the final quiz and question probabilities that were estimated by the algorithm. These probabilities can be used to gain insights into which questions are more difficult or easier for students, and to evaluate the effectiveness of the quiz overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f378f-dced-4a3d-9252-8be53c953f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
