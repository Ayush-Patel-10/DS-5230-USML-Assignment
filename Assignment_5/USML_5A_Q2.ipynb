{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ecbbea-fc15-4e2d-9316-732760453cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from gensim.parsing import strip_tags, strip_numeric, strip_multiple_whitespaces, stem_text, strip_punctuation, remove_stopwords\n",
    "from gensim.parsing import preprocess_string\n",
    "from gensim import parsing\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c65dda-ca2f-443f-b539-591f6f2b1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/patel.ayushj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def kl_summarize (doc_data, num_of_sentences):\n",
    "  summaries = []\n",
    "  for document, file_name in doc_data:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf = True, stop_words = 'english')\n",
    "    document_model = vectorizer.fit_transform([document])\n",
    "    summary = []\n",
    "    picked_sentences = set()\n",
    "    for _ in range(num_of_sentences):\n",
    "      this_sentence = ''\n",
    "      this_sentence_score = float('-inf')\n",
    "      this_sentence_index = 0\n",
    "      for sentence in nltk.sent_tokenize(document):\n",
    "        # print('sampling sentence: ', sentence, '\\n')\n",
    "        if this_sentence_index in picked_sentences: continue\n",
    "        new_sentences = list(map(lambda x:x[0], summary))\n",
    "        new_sentences.append(sentence)\n",
    "        kl_score = kl_similarity(document_model.T.toarray(), vectorizer.transform([' '.join(new_sentences)]).T.toarray())\n",
    "        if kl_score > this_sentence_score:\n",
    "          this_sentence_score = kl_score\n",
    "          this_sentence = (sentence, this_sentence_index)\n",
    "        this_sentence_index += 1\n",
    "      if this_sentence != '':\n",
    "        summary.append(this_sentence)\n",
    "        picked_sentences.add(this_sentence[1])\n",
    "\n",
    "    summary = sorted(summary, key = lambda x: x[1]) \n",
    "    summaries.append(' '.join(list(map(lambda x: x[0], summary))))\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7230550-462c-4567-901c-ef909eca841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def kl_similarity(p, q) :\n",
    "  kl = 0 \n",
    "  lambda_param = 0.1\n",
    "  for i in range(p.shape[0]): \n",
    "    p_i = p[i]\n",
    "    q_i = q[i]\n",
    "    kl += p_i * math.log( (p_i + lambda_param) / (q_i + ( lambda_param * p_i.shape[0] ) ) )\n",
    "  return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eda80a3-a5ba-4099-b1fa-b68ba1461d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1: Using the VMODE command, all you need to do is type VMODE VESA at the dos\n",
      "prompt. VMODE is included with the Speedstar 24.\n",
      "\n",
      "Summary 2: Everything is less than a year old. Thanks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ng_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes')).data\n",
    "ng_data = ng_data[27:29]\n",
    "\n",
    "summaries = kl_summarize(zip(ng_data,ng_data), 2)\n",
    "for i, summary in enumerate(summaries):\n",
    "    print(f'Summary {i+1}: {summary}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469c5249-ceee-432f-ab48-06a302b50076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 03:20:30.043724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 03:20:31.844472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.2/lib64:/shared/centos7/anaconda3/2022.05/lib:/shared/centos7/nodejs/14.15.4/lib:/home/patel.ayushj/.conda/envs/nlp-tf/lib/\n",
      "2023-04-03 03:20:31.844653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.2/lib64:/shared/centos7/anaconda3/2022.05/lib:/shared/centos7/nodejs/14.15.4/lib:/home/patel.ayushj/.conda/envs/nlp-tf/lib/\n",
      "2023-04-03 03:20:31.844672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-04-03 03:20:34.258600: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.2/lib64:/shared/centos7/anaconda3/2022.05/lib:/shared/centos7/nodejs/14.15.4/lib:/home/patel.ayushj/.conda/envs/nlp-tf/lib/\n",
      "2023-04-03 03:20:34.258664: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-03 03:20:34.258701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0437): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from rouge import Rouge\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_string(text, filters):\n",
    "    for f in filters:\n",
    "        text = f(text)\n",
    "    return text.split()\n",
    "\n",
    "def strip_multiple_whitespaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def transform_to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_emails(text):\n",
    "    return re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOP_WORDS])\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "def cleaningPipe(document):\n",
    "    processed_words = preprocess_string(document, [\n",
    "        remove_emails,\n",
    "        strip_multiple_whitespaces, \n",
    "        transform_to_lower,\n",
    "        lemmatize_text\n",
    "    ])\n",
    "    \n",
    "    return processed_words\n",
    "\n",
    "def joinList(processed_words):\n",
    "    return ' '.join(processed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae7b8f8-e5d9-4b79-8407-867e8b12d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'DUC2001'\n",
    "\n",
    "contents = []\n",
    "summaries = []\n",
    "\n",
    "data = { 'Article' : [] , 'Content' : [] , 'Summary' : [] }\n",
    "\n",
    "for name in glob.glob(path + '/*'):\n",
    "    \n",
    "    filename  = os.path.basename(name)\n",
    "    contents = ''\n",
    "    summaries = ''\n",
    "\n",
    "    try:\n",
    "        if filename == 'annotations.txt' or filename in 'notes.txt':\n",
    "            continue\n",
    "            \n",
    "        with open(path + '/Summaries/{}.txt'.format(filename.lower())) as file:\n",
    "            f = file.read()\n",
    "            abs = f.find('Abstract:')\n",
    "            len_abs = len('Abstract:')\n",
    "            intr = f.find('Introduction:')\n",
    "            len_intr = len('Introduction:')\n",
    "            \n",
    "            summaries = f[(abs+len_abs):intr] \n",
    "            contents = f[(intr+len_intr):]\n",
    "            \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    data['Article'].append(filename)\n",
    "    data['Summary'].append(summaries.strip().replace('\\n', ' '))\n",
    "    data['Content'].append(contents.strip().replace('\\n', ' ').replace('    ', ' ').replace(' \\x1a', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c40cce-16ec-4485-9cc6-0566c26c7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "ducDF = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7574e7b-8dc8-4c06-992c-2f4940c71d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP890314-0237</td>\n",
       "      <td>Inside a small motor home, Joanne Pierluissi r...</td>\n",
       "      <td>San Antonio, Texas, with a 50% Hispanic popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA041889-0039</td>\n",
       "      <td>Out of the horn of Africa has emerged the most...</td>\n",
       "      <td>A number of years ago, Ethiopian athletes came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FT923-5089</td>\n",
       "      <td>THERE are growing signs that Hurricane Andrew,...</td>\n",
       "      <td>Hurricane Andrew, the costliest disaster to hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP880811-0299</td>\n",
       "      <td>An annual Agriculture Department survey confir...</td>\n",
       "      <td>President Reagan has signed a $3.9 billion dro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP900322-0192</td>\n",
       "      <td>A stone's throw from the smelly Smithfield mea...</td>\n",
       "      <td>The De Beers diamond cartel faces declining sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>LA092189-0123</td>\n",
       "      <td>A French DC-10 jetliner with 171 people aboard...</td>\n",
       "      <td>A French DC-10 jetliner with 171 on board expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>SJMN91-06193235</td>\n",
       "      <td>It's E-Day. But before you rush out to see whe...</td>\n",
       "      <td>In San Jose, the eclipse will begin at 10:10 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>FT934-9116</td>\n",
       "      <td>THE FIGHT over the North American Free Trade A...</td>\n",
       "      <td>After Vice President Gore's debate victory ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>AP900629-0260</td>\n",
       "      <td>It's been described as the largest current civ...</td>\n",
       "      <td>The \"Chunnel\" between Britain and France is ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>AP900426-0054</td>\n",
       "      <td>Elizabeth Taylor has rallied from a near-fatal...</td>\n",
       "      <td>Elizabeth has rallied from a near fatal bout w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Article                                            Content  \\\n",
       "0      AP890314-0237  Inside a small motor home, Joanne Pierluissi r...   \n",
       "1      LA041889-0039  Out of the horn of Africa has emerged the most...   \n",
       "2         FT923-5089  THERE are growing signs that Hurricane Andrew,...   \n",
       "3      AP880811-0299  An annual Agriculture Department survey confir...   \n",
       "4      AP900322-0192  A stone's throw from the smelly Smithfield mea...   \n",
       "..               ...                                                ...   \n",
       "296    LA092189-0123  A French DC-10 jetliner with 171 people aboard...   \n",
       "297  SJMN91-06193235  It's E-Day. But before you rush out to see whe...   \n",
       "298       FT934-9116  THE FIGHT over the North American Free Trade A...   \n",
       "299    AP900629-0260  It's been described as the largest current civ...   \n",
       "300    AP900426-0054  Elizabeth Taylor has rallied from a near-fatal...   \n",
       "\n",
       "                                               Summary  \n",
       "0    San Antonio, Texas, with a 50% Hispanic popula...  \n",
       "1    A number of years ago, Ethiopian athletes came...  \n",
       "2    Hurricane Andrew, the costliest disaster to hi...  \n",
       "3    President Reagan has signed a $3.9 billion dro...  \n",
       "4    The De Beers diamond cartel faces declining sa...  \n",
       "..                                                 ...  \n",
       "296  A French DC-10 jetliner with 171 on board expl...  \n",
       "297  In San Jose, the eclipse will begin at 10:10 a...  \n",
       "298  After Vice President Gore's debate victory ove...  \n",
       "299  The \"Chunnel\" between Britain and France is ha...  \n",
       "300  Elizabeth has rallied from a near fatal bout w...  \n",
       "\n",
       "[301 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ducDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afe50f4-61a7-40f8-9f65-66a992f7414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ducDF[\"cleaned_articles\"] = ducDF[\"Content\"].apply(cleaningPipe).apply(joinList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ab2b15-75fd-446e-8288-0a2fe520539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUC_data = ducDF['cleaned_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f71385-6675-44fc-91ab-c28f37feebab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"inside a small motor home , joanne pierluissi raise her sleeve as nurse mary perez insert a needle into the vein above her forearm , draw blood into a tube for a diabetes test . as her daughter watch , pierluissi , 24 , say it be for they , as much as for herself , that she agree to be test for the deadly killer of hispanic . twelve million americans have some form of diabetes , but it most prevalent among minority , especially native americans , black and hispanic . hispanic be three time as likely to develop diabetes as the general population , and 40 percent of the 700,000 victim in texas be mexican - american . more than 150,000 americans die from diabete each year ; another 150,000 death be diabetes - relate , accord to the american diabetes association . no one really know what spark it , but researcher believe hispanic could hold the key . san antonio , the nation 's ninth large city , with a population that be 50 percent hispanic , be become the base for diabetes study . san antonio 's hispanic makeup lead dr . ralph defronzo to abandon his prestigious position as a yale university diabete researcher and persuade his four - member team to relocate to the university of texas health science center . epidemiologist dr . michael stern have devote 10 year to study hispanic diabete and lead the grassroots study of the most common form , which develop mostly in obese adult over 40 who may have a family history of the disease . stern say family study of diabetic patient be brine he close to find the gene that trigger the disease , and to a screening test . researcher believe that poor hispanic ' diet of cheap , process food , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctor _ increase their risk of acquire diabete . educate elementary - school - age child about healthy diet would help reduce the number of diabetes case , defronzo say . ` ` if you have a 65 - year - old mother who weigh 220 pound and you tell she to go out and jog five mile monday , wednesday and friday , she be go to laugh at you . '' aly el - shiekh envision astronaut on a three - year trip to mars ` ` knit '' themselves a space station use ceramic fiber that can be braid into panel , beam , box and practically any other shape . ` ` we believe if they can take the ceramic fiber they need and the machinery we be develop they would be able to literally make the space station they will need as they go , '' say el - shiekh , a mechanical engineer at work in north carolina state university 's textile school . el - shiekh and his student be develop machinery to braid long strand of ceramic fiber . such fiber , bond with epoxy , also will form heat shield and many of the part in the vessel that carry people to mars . the part will withstand speed of 50,000 mph and temperature of at least 4,000 degree . while much of his work relate to the mars mission research center here , el - shiekh see a big future for composite material like ceramic fiber . ` ` the day may very well come when you be drive around with car engine part of ceramic fiber , '' he say , add that the vibration - damp property of the material also would make they good for torsion bar in car . ` ` we also be work on the idea of put this braid fabric in concrete as reinforce material instead of metal rod , '' he say . ` ` it be strong than steel , do not rust and would not wear away _ the road would not deteriorate . '' the fiber , include kevlar now use to make bulletproof vest , also could be use to make some body part , and el - shiekh be work with duke university researcher on ceramic ` ` stent , '' collapsible brace for artery . ` ` the possibility be limitless . '' say el - shiekh , who can produce shape range from hollow cube to panel that have opening for wiring and conduit already braid into they . ` ` the big problem be cost and that be why we be work on this automate machinery . '' it be 8 p.m. and a dozen people wait in the lobby of boston city hospital 's emergency room . behind the swinge door , dr . peter moyer be call to a car accident victim who have only slight injury but slip so deeply into unconsciousness he can barely be rouse by two physician . ` ` have you take any drug ? '' doctor ask . ` ` cocaine , heroin , marijuana ? '' it be a question that have become more and more commonplace in emergency room already burden by increase patient load . ` ` there be an emergency in the emergency room right now in not only new york and boston but around the country and for a variety of reason , '' say ken raske , president of the great new york hospital association . drug , and their side effect of aid , violence and psychiatric disorder , play a role in the problem plague big - city emergency room , raske say . from 1986 to 1987 , accord to the national institute on drug abuse , cocaine - relate case in emergency room increase 122 percent in the district of columbia ; 86 percent in both boston and atlanta ; 80 percent in detroit ; 73 percent in chicago ; 53 percent in minneapolis ; 50 percent in texas , and 39 percent in new york city . effort to stem the rise tide of drug abuse come at a time when emergency room already face increase patient load , partly because of the reduced role of the traditional family doctor and partly because there be more people who can not afford a private doctor . ` ` it be really provide a major backlog in the emergency department system , '' say diane howard , director of the american hospital association 's division of ambulatory care and health promotion . ` ` the bottom line be that emergency care be be squeeze , '' raske say . ` ` the real loser here be the patient . ''\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUC_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5f8192-e3a0-4f0b-b4ee-1f764cb12b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"San Antonio, Texas, with a 50% Hispanic population, has become a center for the study of diabetes in Hispanics. Dr. Ralph DeFronzo left his diabetes research center at Yale University to relocate to the University of Texas at San Antonio to study the local population. His researchers are reaching out in a mobile home which roams the neighborhoods and tests inhabitants for the disease. Dr. DeFronzo's researchers believe that poor Hispanics' diet of cheap processed foods, their lack of exercise and infrequent medical attention are the root causes of their predisposition. They believe education of children may be critical.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ducDF[\"Summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125a741b-406f-4424-a25f-f4a633e00243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudy weather saturday threaten to mar the show for thousand of finnish and foreign skygazer hope to glimpse a total solar eclipse in this land of the midnight sun . the solar eclipse in finland start at 4:03 a.m. sunday ( 9:03 p.m. edt saturday ) . at that time , the moon will begin gradually move between the earth and the sun . the total eclipse begin at 4:52 a.m. in helsinki and will last 83 second . the eclipse end at 5:45 a.m. in helsinki . some eclipse viewer will not have to worry about the cloud , because they will be above they . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kl_summaries = kl_summarize(zip(DUC_data[100:101], DUC_data[100:101]) , 8)\n",
    "\n",
    "for i in kl_summaries:\n",
    "  print (i, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7999f809-9213-4eaf-8d16-16479fe3cc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'f': 0.350710895474046, 'p': 0.3523809523809524, 'r': 0.3490566037735849}, 'rouge-2': {'f': 0.10526315289485155, 'p': 0.10576923076923077, 'r': 0.10476190476190476}, 'rouge-l': {'f': 0.2535211217962707, 'p': 0.27692307692307694, 'r': 0.23376623376623376}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "references = [ducDF['Summary'][100]] \n",
    "\n",
    "scores = rouge.get_scores(kl_summaries, references, avg = True)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cefaf-943a-4504-8a53-176fe8914517",
   "metadata": {},
   "source": [
    "<b>Observation: </b> <br>\n",
    "As we can see that the model performs well for unigram that is the rouge-1 is 0.35. But when it comes to bigram model (rouge-2) we have a lower f1-score, precision and recall. Thus we can infer that the KL_summarizer is only good for unigram models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bd0d0-688c-4431-99fd-56c431dbbf88",
   "metadata": {},
   "source": [
    "# Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe78540-5dbb-4376-8149-daee2c51fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_summarize(doc_data, num_of_sentences, num_of_topics=1000, num_of_top_words=20):\n",
    "  summaries = []\n",
    "  for document in doc_data:\n",
    "    # LDA model\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english')\n",
    "    document_model = vectorizer.fit_transform([document])\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=num_of_topics, max_iter=20, random_state=42)\n",
    "    lda.fit(document_model)\n",
    "\n",
    "    # Get the most probable words for each topic\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topic_words = []\n",
    "    for topic in lda.components_:\n",
    "        word_idx = np.argsort(topic)[::-1][:num_of_top_words]\n",
    "        topic_words.append([feature_names[i] for i in word_idx])\n",
    "\n",
    "    # Get the topic distribution for each sentence\n",
    "    sentence_topics = []\n",
    "    for sentence in nltk.sent_tokenize(document):\n",
    "        sentence_model = vectorizer.transform([sentence])\n",
    "        sentence_topics.append(lda.transform(sentence_model)[0])\n",
    "\n",
    "    # Pick the top sentences based on the topic diversity\n",
    "    summary = []\n",
    "    picked_sentences = set()\n",
    "    while len(summary) < num_of_sentences:\n",
    "        best_sentence = None\n",
    "        best_score = 0\n",
    "        for i, sentence in enumerate(sentence_topics):\n",
    "            if i in picked_sentences: continue\n",
    "            sentence_score = sum([sentence[j]*sentence_topics[j][k] for j in range(len(sentence_topics)) for k in range(num_of_topics)])\n",
    "            if sentence_score > best_score:\n",
    "                best_sentence = i\n",
    "                best_score = sentence_score\n",
    "        if best_sentence is None: break\n",
    "        summary.append((nltk.sent_tokenize(document)[best_sentence], best_sentence))\n",
    "        picked_sentences.add(best_sentence)\n",
    "\n",
    "    summary = sorted(summary, key=lambda x: x[1])\n",
    "    summaries.append(' '.join(list(map(lambda x: x[0], summary))))\n",
    "  return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b52353-086d-4912-9ae4-2f57886a01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1: Using the VMODE command, all you need to do is type VMODE VESA at the dos\n",
      "prompt. VMODE is included with the Speedstar 24.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ng_data = fetch_20newsgroups(subset = 'all', remove = ('headers', 'footers', 'quotes')).data\n",
    "ng_data = ng_data[27:28]\n",
    "\n",
    "summaries = lda_summarize(ng_data, 2)\n",
    "for i, summary in enumerate(summaries):\n",
    "    print(f'Summary {i+1}: {summary}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2ed7d44-3120-47e1-b027-1a4415975866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1: cloudy weather saturday threaten to mar the show for thousand of finnish and foreign skygazer hope to glimpse a total solar eclipse in this land of the midnight sun . the weather forecast take a turn for the bad in the evening , when the finnish meteorological service predict cloudy weather with a chance of shower for eastern finland on sunday . in the eastern town of joensuu , a television news broadcast late saturday show it be already cloudy there with a light drizzle fall . the solar eclipse in finland start at 4:03 a.m. sunday ( 9:03 p.m. edt saturday ) . at that time , the moon will begin gradually move between the earth and the sun . the total eclipse begin at 4:52 a.m. in helsinki and will last 83 second . after the total phase of the eclipse , the moon will move away , uncover more and more of the sun . the eclipse end at 5:45 a.m. in helsinki .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaries = lda_summarize(DUC_data[100:101], 8)\n",
    "for i, summary in enumerate(summaries):\n",
    "    print(f'Summary {i+1}: {summary}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b3d3b36-ae5b-4a23-b938-030b05da112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A total eclipse will arc from southeast Finland, across northeastern U.S.S.R to the Alaskan Aleutian Islands. The best place for observation will be in the Soviet Union. In Helsinki, the total eclipse begins at 4:52 a.m. and will last 83 seconds. Best viewing in Finland will be in Joensuu, where about 10,000 people, including 3000 foreigners are expected to converge. In Joensuu the sun will be 5 degrees above the horizon, compared with 1 degree above in Helsinki. Skies may be cloudy. Some viewers will be above the clouds. Finnair, the national airline, and some private companies are offering eclipse viewing flights.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ducDF['Summary'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5277a02c-ec23-4c57-8b06-b4de8fd1f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'f': 0.2527880993137188, 'p': 0.2085889570552147, 'r': 0.32075471698113206}, 'rouge-2': {'f': 0.07490636226907407, 'p': 0.06172839506172839, 'r': 0.09523809523809523}, 'rouge-l': {'f': 0.20858895207045816, 'p': 0.19767441860465115, 'r': 0.22077922077922077}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "references = [ducDF['Summary'][100]] \n",
    "\n",
    "scores = rouge.get_scores(summaries, references, avg = True)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea2482-bb76-4540-b882-a039aaac8f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
